<!DOCTYPE html>
<html>
<head>
    <title>VRM Speech Lip-Sync Demo</title>
    <meta name="description" content="Demonstrates audio-driven lip-sync using Rhubarb">
    <script src="js/aframe-v1.7.1.js"></script>
    <script src="js/aframe-environment-component.js"></script>
    <script src="js/three-vrm.js"></script>
    <script src="js/three-vrm-animation.js"></script>
    <script src="js/aframe-vrm-bundle.js"></script>
</head>
<body>

<style>
    #info {
        position: fixed;
        top: 20px;
        left: 20px;
        color: white;
        font-family: monospace;
        background: rgba(0,0,0,0.8);
        padding: 15px;
        border-radius: 5px;
        z-index: 100;
        font-size: 1.2em;
    }
    .highlight {
        color: #00ff00;
        font-weight: bold;
    }
    #controls {
        position: fixed;
        bottom: 20px;
        left: 20px;
        background: rgba(0,0,0,0.8);
        padding: 15px;
        border-radius: 5px;
        z-index: 100;
    }
    button {
        background: #00ff00;
        color: black;
        border: none;
        padding: 10px 20px;
        font-size: 1em;
        border-radius: 3px;
        cursor: pointer;
        font-family: monospace;
        margin: 5px;
    }
    button:hover {
        background: #00cc00;
    }
</style>

<div id="info">
    <div>Speech Lip-Sync Demo</div>
    <div id="status">Loading model...</div>
    <div id="current-viseme" class="highlight"></div>
    <div id="audio-time"></div>
</div>

<div id="controls">
    <button id="playBtn">Play Audio</button>
    <button id="stopBtn">Stop</button>
</div>

<script>
    // Rhubarb mouth cue to our viseme mapping
    const RHUBARB_TO_VISEME = {
        'X': null,        // Rest position (neutral)
        'A': 'A',         // Open mouth (father)
        'B': 'M',         // Lips together (M, B, P)
        'C': 'O',         // Rounded mouth (O, U)
        'D': 'E',         // Wide mouth (E, I) - using E as primary
        'E': 'E',         // Relaxed mouth (schwa)
        'F': 'F',         // Upper teeth on lower lip (F, V)
        'G': 'K',         // Back of tongue (K, G)
        'H': 'S'          // Tongue tip up (L, R, S)
    };

    AFRAME.registerComponent('speech-lipsync', {
        schema: {
            vrm: { type: 'string', default: 'models/AIAN/AIAN_F_1_Casual_CLEANED.vrm' },
            audio: { type: 'string', default: 'audio/houston.wav' },
            timings: { type: 'string', default: 'audio/houston.json' }
        },

        init: function () {
            this.vrm = null;
            this.mesh = null;
            this.audio = null;
            this.mouthCues = [];
            this.currentCueIndex = 0;
            this.isPlaying = false;

            // Bindings
            this.onModelLoaded = this.onModelLoaded.bind(this);
            this.el.addEventListener('model-loaded', this.onModelLoaded);

            // Set VRM src
            this.el.setAttribute('vrm', 'src', this.data.vrm);

            // Setup audio
            this.setupAudio();

            // Load timing data
            this.loadTimingData();

            // Setup UI controls
            this.setupControls();
        },

        onModelLoaded: function (evt) {
            const vrm = evt.detail.vrm;
            if (!vrm) return;

            this.vrm = vrm;
            console.log("VRM loaded");
            document.getElementById('status').textContent = "Model Loaded. Press Play to start.";

            // Find the face mesh
            this.mesh = this.findFaceMesh(this.vrm.scene);
            if (this.mesh) {
                console.log("Face mesh found:", this.mesh.name);
            } else {
                console.warn("Face mesh not found");
            }
        },

        findFaceMesh: function(root) {
            let found = null;
            root.traverse((node) => {
                if (node.isMesh && node.name === 'H_DDS_HighRes') {
                    found = node;
                }
            });
            return found;
        },

        setupAudio: function() {
            this.audio = new Audio(this.data.audio);
            this.audio.addEventListener('ended', () => {
                this.isPlaying = false;
                this.resetVisemes();
                document.getElementById('status').textContent = "Audio finished. Press Play again.";
            });
        },

        loadTimingData: function() {
            fetch(this.data.timings)
                .then(response => response.json())
                .then(data => {
                    this.mouthCues = data.mouthCues;
                    console.log(`Loaded ${this.mouthCues.length} mouth cues`);
                    console.log('Duration:', data.metadata.duration, 'seconds');
                })
                .catch(error => {
                    console.error('Error loading timing data:', error);
                });
        },

        setupControls: function() {
            document.getElementById('playBtn').addEventListener('click', () => {
                if (!this.audio || !this.mouthCues.length) {
                    alert('Audio or timing data not loaded yet!');
                    return;
                }
                this.play();
            });

            document.getElementById('stopBtn').addEventListener('click', () => {
                this.stop();
            });
        },

        play: function() {
            this.audio.currentTime = 0;
            this.audio.play();
            this.isPlaying = true;
            this.currentCueIndex = 0;
            document.getElementById('status').textContent = "Playing: Houston, we have a problem.";
        },

        stop: function() {
            this.audio.pause();
            this.audio.currentTime = 0;
            this.isPlaying = false;
            this.currentCueIndex = 0;
            this.resetVisemes();
            document.getElementById('status').textContent = "Stopped.";
        },

        resetVisemes: function() {
            if (!this.mesh) return;

            // Set all visemes to 0
            ['A', 'I', 'U', 'E', 'O', 'F', 'M', 'S', 'CH', 'K', 'N'].forEach(viseme => {
                this.applyViseme(viseme, 0);
            });

            document.getElementById('current-viseme').textContent = '';
        },

        tick: function(t, dt) {
            if (!this.isPlaying || !this.audio || !this.mouthCues.length) return;

            const currentTime = this.audio.currentTime;

            // Update time display
            document.getElementById('audio-time').textContent =
                `Time: ${currentTime.toFixed(2)}s`;

            // Find current mouth cue
            while (this.currentCueIndex < this.mouthCues.length - 1 &&
                   currentTime >= this.mouthCues[this.currentCueIndex + 1].start) {
                this.currentCueIndex++;
            }

            const currentCue = this.mouthCues[this.currentCueIndex];
            if (currentCue && currentTime >= currentCue.start && currentTime < currentCue.end) {
                // Calculate intensity based on position in cue
                const cueProgress = (currentTime - currentCue.start) / (currentCue.end - currentCue.start);

                // Use sine wave for smooth transition
                // Peaks at middle of cue, fades in/out
                const intensity = Math.sin(cueProgress * Math.PI);

                // Get our viseme from Rhubarb cue
                const rhubarbCue = currentCue.value;
                const ourViseme = RHUBARB_TO_VISEME[rhubarbCue];

                // Reset all visemes first
                ['A', 'I', 'U', 'E', 'O', 'F', 'M', 'S', 'CH', 'K', 'N'].forEach(v => {
                    this.applyViseme(v, 0);
                });

                // Apply current viseme
                if (ourViseme) {
                    this.applyViseme(ourViseme, intensity);

                    // Update UI
                    document.getElementById('current-viseme').textContent =
                        `${rhubarbCue} → ${ourViseme} : ${intensity.toFixed(2)}`;
                } else {
                    // Rest position
                    document.getElementById('current-viseme').textContent =
                        `${rhubarbCue} → rest`;
                }
            }
        },

        applyViseme: function(name, value) {
            // Direct mesh access for all visemes
            if (this.mesh && this.mesh.morphTargetDictionary && this.mesh.morphTargetInfluences) {
                if (name in this.mesh.morphTargetDictionary) {
                    const idx = this.mesh.morphTargetDictionary[name];
                    this.mesh.morphTargetInfluences[idx] = value;
                }
            }
        }
    });
</script>

<a-scene>
    <a-sky color="#1a1a1a"></a-sky>

    <!-- Lighting -->
    <a-entity light="type: ambient; intensity: 0.6;"></a-entity>
    <a-entity light="type: directional; intensity: 1.0; castShadow: true;" position="1 2 3"></a-entity>
    <a-entity light="type: point; intensity: 0.5; color: #ffd;" position="-1 1.5 1"></a-entity>

    <!-- Camera: Close up on face -->
    <a-entity position="0 0 0.6">
        <a-camera fov="50" wasd-controls-enabled="true" look-controls-enabled="true"></a-camera>
        <!-- Headlight for face visibility -->
        <a-entity light="type: point; intensity: 0.8; distance: 3; decay: 2" position="0 1.6 0"></a-entity>
    </a-entity>

    <!-- Avatar with Speech Lip-Sync -->
    <a-entity
        id="avatar"
        speech-lipsync="
            vrm: models/AIAN/AIAN_F_1_Casual_CLEANED.vrm;
            audio: audio/houston.wav;
            timings: audio/houston.json
        "
        position="0 0 0"
        rotation="0 180 0"
        shadow="cast: true">
    </a-entity>

</a-scene>

</body>
</html>
